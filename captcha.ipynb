{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import string\n",
    "from PIL import Image \n",
    "import time\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate train dataset: \n",
      " ----------------------------------------\n",
      "generating captcha  1999\n",
      "generating captcha  3999\n",
      "generating captcha  5999\n",
      "generating captcha  7999\n",
      "generating captcha  9999\n",
      "generate test dataset: \n",
      " ----------------------------------------\n",
      "generating captcha  199\n",
      "generating captcha  399\n",
      "generating captcha  599\n",
      "generating captcha  799\n",
      "generating captcha  999\n"
     ]
    }
   ],
   "source": [
    "#image = ImageCaptcha(fonts=['./font/AntykwaBold.ttf', './font/Candice.ttf', './font/VeraMono.ttf', './font/verdana.ttf'])\n",
    "\n",
    "# %%timeit\n",
    "# X = []\n",
    "# for i in range(1000):\n",
    "#     text = ''.join(random.sample(char_map, 4))\n",
    "#     img = np.array(image.generate_image(text).resize((100, 40)))\n",
    "#     img_gray = np.mean(img, -1)\n",
    "#     if not isinstance(X, np.ndarray):\n",
    "#         X = img_gray[..., np.newaxis]\n",
    "#     else:\n",
    "#         X = np.concatenate((X, img_gray[..., np.newaxis]), axis=-1)\n",
    "#     #灰度值求解\n",
    "#     #np.sum(np.array([0.2989, 0.5870, 0.1140]) * img, axis=2)\n",
    "#     if i % 100 == 0:\n",
    "#         print(\"generating captcha \" , i)\n",
    "\n",
    "num_char = 4\n",
    "num_images_train = 10000\n",
    "num_images_test = 1000\n",
    "width_images = 100\n",
    "height_images = 40\n",
    "num_charmap = 36\n",
    "num_channel = 1\n",
    "char_map = string.ascii_uppercase + string.digits\n",
    "\n",
    "\n",
    "\n",
    "image_generator = ImageCaptcha(fonts=['./font/AntykwaBold.ttf'])\n",
    "\n",
    "def dataset_generator(num_images):\n",
    "    X = np.empty((num_images, height_images, width_images))\n",
    "    y = np.empty((num_images, num_charmap*num_char))\n",
    "    for i in range(num_images):\n",
    "        text = ''.join(random.sample(char_map, num_char))\n",
    "        img = np.array(image_generator.generate_image(text).resize((width_images, height_images)))\n",
    "        img_gray = np.mean(img, -1)\n",
    "        img_scale = np.multiply(img_gray, 1/255.0)\n",
    "        X[i, :, :] = img_scale\n",
    "        y_index = [ char_map.find(text[_i])+_i*num_charmap for _i in range(num_char)]\n",
    "        y[i, y_index] = 1\n",
    "\n",
    "        #灰度值求解\n",
    "        #np.sum(np.array([0.2989, 0.5870, 0.1140]) * img, axis=2)\n",
    "        if (i+1) % (num_images/5) == 0:\n",
    "            print(\"generating captcha \" , i)\n",
    "    return X, y\n",
    "\n",
    "print(\"generate train dataset: \\n\", '-'*40)\n",
    "X_train, y_train = dataset_generator(num_images_train)\n",
    "print(\"generate test dataset: \\n\", '-'*40)\n",
    "X_test, y_test = dataset_generator(num_images_test)\n",
    "y_test = np.reshape(y_test, [-1, num_char, num_charmap])        \n",
    "def generator(X, y, batch_size=100):\n",
    "    index_in_epoch = 0\n",
    "    num_images = X.shape[0]\n",
    "    while True:\n",
    "        start = index_in_epoch\n",
    "        index_in_epoch += batch_size\n",
    "        if index_in_epoch > num_images:\n",
    "            perm = np.arange(num_images)\n",
    "            np.random.shuffle(perm)\n",
    "            X = X[perm]\n",
    "            y = y[perm]\n",
    "            start = 0\n",
    "            index_in_epoch = batch_size\n",
    "            assert batch_size <= num_images\n",
    "        end = index_in_epoch\n",
    "        yield X[start:end], y[start:end]     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, [None, height_images, width_images])\n",
    "y_ = tf.placeholder(tf.float32, [None, num_char, num_charmap])\n",
    "\n",
    "#todo: find out why reshape doesn.t work\n",
    "x_image = tf.reshape(x, [-1, height_images, width_images, 1])\n",
    "# y_ = tf.reshape(y_, [-1, num_char, num_charmap])\n",
    "\n",
    "#First Convolutional Layer\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#Second Convolutional Layer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#Third Convolutional Layer\n",
    "# W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "# b_conv3 = bias_variable([128])\n",
    "# h_conv3 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "# h_pool3 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#First densely Connected Layer\n",
    "W_fc1 = weight_variable([10 * 25 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 10*25*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "#Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Readout Layer\n",
    "W_fc2 = weight_variable([1024, 144])\n",
    "b_fc2 = bias_variable([144])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#cross_entropy_1 无法导向正确结果，废弃\n",
    "#cross_entropy_1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))\n",
    "#分别计算每个char的softmax损失函数，取其平均值作为整体的损失函数\n",
    "\n",
    "\n",
    "y_conv = tf.reshape(y_conv, [-1, num_char, num_charmap])\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.concat(0, [tf.nn.softmax_cross_entropy_with_logits(y_conv[:, _i ,:], y_[:, _i,:]) \n",
    "                  for _i in range(num_char) ]))\n",
    "\n",
    "# cross_entropy = tf.reduce_mean(\n",
    "#     tf.concat(0, [tf.nn.softmax_cross_entropy_with_logits(\n",
    "#         y_conv[:, num_charmap*i:num_charmap*(i+1)-1], y_[:, num_charmap*i:num_charmap*(i+1)-1]) \n",
    "#                   for i in range(num_char) ]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "max_idx_p = tf.argmax(y_conv, 2)\n",
    "max_idx_l = tf.argmax(y_, 2)\n",
    "correct_prediction = tf.cast(tf.equal(max_idx_p, max_idx_l), tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.reduce_min(correct_prediction, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  5 19:49:39 2017 : train cnn begin, amount 20000 steps\n",
      "Thu Jan  5 19:53:09 2017 : step 99, training accuracy 0\n",
      "Thu Jan  5 19:56:43 2017 : step 199, training accuracy 0\n",
      "Thu Jan  5 20:00:41 2017 : step 299, training accuracy 0\n",
      "Thu Jan  5 20:04:32 2017 : step 399, training accuracy 0\n",
      "Thu Jan  5 20:08:23 2017 : step 499, training accuracy 0\n",
      "Thu Jan  5 20:12:11 2017 : step 599, training accuracy 0\n",
      "Thu Jan  5 20:16:04 2017 : step 699, training accuracy 0\n",
      "Thu Jan  5 20:20:05 2017 : step 799, training accuracy 0\n",
      "Thu Jan  5 20:24:05 2017 : step 899, training accuracy 0\n",
      "Thu Jan  5 20:28:01 2017 : step 999, training accuracy 0\n",
      "Thu Jan  5 20:32:02 2017 : step 1099, training accuracy 0\n",
      "Thu Jan  5 20:35:41 2017 : step 1199, training accuracy 0\n",
      "Thu Jan  5 20:39:36 2017 : step 1299, training accuracy 0\n",
      "Thu Jan  5 20:43:36 2017 : step 1399, training accuracy 0\n",
      "Thu Jan  5 20:47:39 2017 : step 1499, training accuracy 0\n",
      "Thu Jan  5 20:51:36 2017 : step 1599, training accuracy 0\n",
      "Thu Jan  5 20:55:15 2017 : step 1699, training accuracy 0\n",
      "Thu Jan  5 20:59:00 2017 : step 1799, training accuracy 0\n",
      "Thu Jan  5 21:02:53 2017 : step 1899, training accuracy 0\n",
      "Thu Jan  5 21:06:42 2017 : step 1999, training accuracy 0\n",
      "Thu Jan  5 21:10:45 2017 : step 2099, training accuracy 0\n",
      "Thu Jan  5 21:15:14 2017 : step 2199, training accuracy 0\n",
      "Thu Jan  5 21:19:57 2017 : step 2299, training accuracy 0\n",
      "Thu Jan  5 21:24:43 2017 : step 2399, training accuracy 0\n",
      "Thu Jan  5 21:28:30 2017 : step 2499, training accuracy 0\n",
      "Thu Jan  5 21:32:04 2017 : step 2599, training accuracy 0\n",
      "Thu Jan  5 21:36:37 2017 : step 2699, training accuracy 0\n",
      "Thu Jan  5 21:40:36 2017 : step 2799, training accuracy 0\n",
      "Thu Jan  5 21:44:04 2017 : step 2899, training accuracy 0\n",
      "Thu Jan  5 21:48:24 2017 : step 2999, training accuracy 0\n",
      "Thu Jan  5 21:52:14 2017 : step 3099, training accuracy 0\n",
      "Thu Jan  5 21:56:28 2017 : step 3199, training accuracy 0\n",
      "Thu Jan  5 22:00:08 2017 : step 3299, training accuracy 0\n",
      "Thu Jan  5 22:02:57 2017 : step 3399, training accuracy 0\n",
      "Thu Jan  5 22:05:48 2017 : step 3499, training accuracy 0.0078125\n",
      "Thu Jan  5 22:09:03 2017 : step 3599, training accuracy 0\n",
      "Thu Jan  5 22:12:09 2017 : step 3699, training accuracy 0.0078125\n",
      "Thu Jan  5 22:16:14 2017 : step 3799, training accuracy 0.03125\n",
      "Thu Jan  5 22:19:11 2017 : step 3899, training accuracy 0.0078125\n",
      "Thu Jan  5 22:22:35 2017 : step 3999, training accuracy 0.015625\n",
      "Thu Jan  5 22:26:48 2017 : step 4099, training accuracy 0.0234375\n",
      "Thu Jan  5 22:30:52 2017 : step 4199, training accuracy 0.015625\n",
      "Thu Jan  5 22:35:04 2017 : step 4299, training accuracy 0.0390625\n",
      "Thu Jan  5 22:39:09 2017 : step 4399, training accuracy 0.0390625\n",
      "Thu Jan  5 22:43:07 2017 : step 4499, training accuracy 0.03125\n",
      "Thu Jan  5 22:46:48 2017 : step 4599, training accuracy 0.0859375\n",
      "Thu Jan  5 22:50:46 2017 : step 4699, training accuracy 0.0625\n",
      "Thu Jan  5 22:54:30 2017 : step 4799, training accuracy 0.0703125\n",
      "Thu Jan  5 22:58:19 2017 : step 4899, training accuracy 0.0859375\n",
      "Thu Jan  5 23:02:03 2017 : step 4999, training accuracy 0.101562\n",
      "Thu Jan  5 23:05:42 2017 : step 5099, training accuracy 0.078125\n",
      "Thu Jan  5 23:09:35 2017 : step 5199, training accuracy 0.171875\n",
      "Thu Jan  5 23:13:23 2017 : step 5299, training accuracy 0.171875\n",
      "Thu Jan  5 23:17:10 2017 : step 5399, training accuracy 0.125\n",
      "Thu Jan  5 23:20:58 2017 : step 5499, training accuracy 0.179688\n",
      "Thu Jan  5 23:24:51 2017 : step 5599, training accuracy 0.195312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a6234f8cf61d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\": step %d, training accuracy %g\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m print(time.ctime() ,\": test accuracy %g\"%accuracy.eval(feed_dict={\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#training\n",
    "y_test = np.reshape(y_test, [-1, num_char, num_charmap])\n",
    "sess.run(tf.global_variables_initializer())\n",
    "trainset_ge = generator(X_train, y_train, batch_size=128)\n",
    "num_loop = 20000\n",
    "print(time.ctime() ,\": train cnn begin, amount %d steps\"%num_loop)\n",
    "for i in range(num_loop):\n",
    "    X_batch, y_batch = next(trainset_ge)\n",
    "    y_batch = y_batch.reshape(-1, num_char, num_charmap)\n",
    "    if (i+1)%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:X_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        print(time.ctime() ,\": step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: X_batch, y_: y_batch, keep_prob: 0.5})\n",
    "\n",
    "print(time.ctime() ,\": test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: X_test, y_: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  5 19:42:55 2017 : train cnn begin, amount 100 steps\n",
      "Thu Jan  5 19:42:56 2017 : step 0, training accuracy 0\n",
      "Thu Jan  5 19:42:57 2017 : step 1, training accuracy 0\n",
      "Thu Jan  5 19:42:59 2017 : step 2, training accuracy 0\n",
      "Thu Jan  5 19:43:00 2017 : step 3, training accuracy 0\n",
      "Thu Jan  5 19:43:01 2017 : step 4, training accuracy 0\n",
      "Thu Jan  5 19:43:03 2017 : step 5, training accuracy 0\n",
      "Thu Jan  5 19:43:04 2017 : step 6, training accuracy 0\n",
      "Thu Jan  5 19:43:05 2017 : step 7, training accuracy 0\n",
      "Thu Jan  5 19:43:07 2017 : step 8, training accuracy 0\n",
      "Thu Jan  5 19:43:08 2017 : step 9, training accuracy 0\n",
      "Thu Jan  5 19:43:10 2017 : step 10, training accuracy 0\n",
      "Thu Jan  5 19:43:11 2017 : step 11, training accuracy 0\n",
      "Thu Jan  5 19:43:13 2017 : step 12, training accuracy 0\n",
      "Thu Jan  5 19:43:14 2017 : step 13, training accuracy 0\n",
      "Thu Jan  5 19:43:16 2017 : step 14, training accuracy 0\n",
      "Thu Jan  5 19:43:17 2017 : step 15, training accuracy 0\n",
      "Thu Jan  5 19:43:18 2017 : step 16, training accuracy 0\n",
      "Thu Jan  5 19:43:20 2017 : step 17, training accuracy 0\n",
      "Thu Jan  5 19:43:21 2017 : step 18, training accuracy 0\n",
      "Thu Jan  5 19:43:23 2017 : step 19, training accuracy 0\n",
      "Thu Jan  5 19:43:24 2017 : step 20, training accuracy 0\n",
      "Thu Jan  5 19:43:26 2017 : step 21, training accuracy 0\n",
      "Thu Jan  5 19:43:27 2017 : step 22, training accuracy 0\n",
      "Thu Jan  5 19:43:28 2017 : step 23, training accuracy 0\n",
      "Thu Jan  5 19:43:30 2017 : step 24, training accuracy 0\n",
      "Thu Jan  5 19:43:31 2017 : step 25, training accuracy 0\n",
      "Thu Jan  5 19:43:33 2017 : step 26, training accuracy 0\n",
      "Thu Jan  5 19:43:34 2017 : step 27, training accuracy 0\n",
      "Thu Jan  5 19:43:36 2017 : step 28, training accuracy 0\n",
      "Thu Jan  5 19:43:38 2017 : step 29, training accuracy 0\n",
      "Thu Jan  5 19:43:39 2017 : step 30, training accuracy 0\n",
      "Thu Jan  5 19:43:41 2017 : step 31, training accuracy 0\n",
      "Thu Jan  5 19:43:42 2017 : step 32, training accuracy 0\n",
      "Thu Jan  5 19:43:43 2017 : step 33, training accuracy 0\n",
      "Thu Jan  5 19:43:45 2017 : step 34, training accuracy 0\n",
      "Thu Jan  5 19:43:46 2017 : step 35, training accuracy 0\n",
      "Thu Jan  5 19:43:48 2017 : step 36, training accuracy 0\n",
      "Thu Jan  5 19:43:50 2017 : step 37, training accuracy 0\n",
      "Thu Jan  5 19:43:51 2017 : step 38, training accuracy 0\n",
      "Thu Jan  5 19:43:52 2017 : step 39, training accuracy 0\n",
      "Thu Jan  5 19:43:54 2017 : step 40, training accuracy 0\n",
      "Thu Jan  5 19:43:55 2017 : step 41, training accuracy 0\n",
      "Thu Jan  5 19:43:57 2017 : step 42, training accuracy 0\n",
      "Thu Jan  5 19:43:58 2017 : step 43, training accuracy 0\n",
      "Thu Jan  5 19:44:00 2017 : step 44, training accuracy 0\n",
      "Thu Jan  5 19:44:02 2017 : step 45, training accuracy 0\n",
      "Thu Jan  5 19:44:03 2017 : step 46, training accuracy 0\n",
      "Thu Jan  5 19:44:04 2017 : step 47, training accuracy 0\n",
      "Thu Jan  5 19:44:06 2017 : step 48, training accuracy 0\n",
      "Thu Jan  5 19:44:07 2017 : step 49, training accuracy 0\n",
      "Thu Jan  5 19:44:09 2017 : step 50, training accuracy 0\n",
      "Thu Jan  5 19:44:10 2017 : step 51, training accuracy 0\n",
      "Thu Jan  5 19:44:12 2017 : step 52, training accuracy 0\n",
      "Thu Jan  5 19:44:13 2017 : step 53, training accuracy 0\n",
      "Thu Jan  5 19:44:15 2017 : step 54, training accuracy 0\n",
      "Thu Jan  5 19:44:16 2017 : step 55, training accuracy 0\n",
      "Thu Jan  5 19:44:17 2017 : step 56, training accuracy 0\n",
      "Thu Jan  5 19:44:19 2017 : step 57, training accuracy 0\n",
      "Thu Jan  5 19:44:20 2017 : step 58, training accuracy 0\n",
      "Thu Jan  5 19:44:22 2017 : step 59, training accuracy 0\n",
      "Thu Jan  5 19:44:23 2017 : step 60, training accuracy 0\n",
      "Thu Jan  5 19:44:25 2017 : step 61, training accuracy 0\n",
      "Thu Jan  5 19:44:26 2017 : step 62, training accuracy 0\n",
      "Thu Jan  5 19:44:27 2017 : step 63, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:29 2017 : step 64, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:30 2017 : step 65, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:32 2017 : step 66, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:33 2017 : step 67, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:35 2017 : step 68, training accuracy 0.03125\n",
      "Thu Jan  5 19:44:36 2017 : step 69, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:38 2017 : step 70, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:39 2017 : step 71, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:40 2017 : step 72, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:42 2017 : step 73, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:43 2017 : step 74, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:45 2017 : step 75, training accuracy 0.015625\n",
      "Thu Jan  5 19:44:46 2017 : step 76, training accuracy 0.03125\n",
      "Thu Jan  5 19:44:48 2017 : step 77, training accuracy 0.03125\n",
      "Thu Jan  5 19:44:49 2017 : step 78, training accuracy 0.046875\n",
      "Thu Jan  5 19:44:51 2017 : step 79, training accuracy 0.09375\n",
      "Thu Jan  5 19:44:52 2017 : step 80, training accuracy 0.09375\n",
      "Thu Jan  5 19:44:54 2017 : step 81, training accuracy 0.078125\n",
      "Thu Jan  5 19:44:55 2017 : step 82, training accuracy 0.078125\n",
      "Thu Jan  5 19:44:57 2017 : step 83, training accuracy 0.0625\n",
      "Thu Jan  5 19:44:59 2017 : step 84, training accuracy 0.0625\n",
      "Thu Jan  5 19:45:00 2017 : step 85, training accuracy 0.046875\n",
      "Thu Jan  5 19:45:02 2017 : step 86, training accuracy 0.0625\n",
      "Thu Jan  5 19:45:03 2017 : step 87, training accuracy 0.0625\n",
      "Thu Jan  5 19:45:04 2017 : step 88, training accuracy 0.0625\n",
      "Thu Jan  5 19:45:06 2017 : step 89, training accuracy 0.0625\n",
      "Thu Jan  5 19:45:08 2017 : step 90, training accuracy 0.09375\n",
      "Thu Jan  5 19:45:09 2017 : step 91, training accuracy 0.109375\n",
      "Thu Jan  5 19:45:11 2017 : step 92, training accuracy 0.125\n",
      "Thu Jan  5 19:45:12 2017 : step 93, training accuracy 0.109375\n",
      "Thu Jan  5 19:45:13 2017 : step 94, training accuracy 0.09375\n",
      "Thu Jan  5 19:45:15 2017 : step 95, training accuracy 0.09375\n",
      "Thu Jan  5 19:45:16 2017 : step 96, training accuracy 0.09375\n",
      "Thu Jan  5 19:45:17 2017 : step 97, training accuracy 0.125\n",
      "Thu Jan  5 19:45:19 2017 : step 98, training accuracy 0.140625\n",
      "Thu Jan  5 19:45:20 2017 : step 99, training accuracy 0.140625\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1000, 144) for Tensor 'Placeholder_1:0', which has shape '(?, 4, 36)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fd812c11a408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m print(time.ctime() ,\": test accuracy %g\"%accuracy.eval(feed_dict={\n\u001b[0;32m---> 15\u001b[0;31m     x: X_test, y_: y_test, keep_prob: 1.0}))\n\u001b[0m",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3631\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3632\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3633\u001b[0;31m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1000, 144) for Tensor 'Placeholder_1:0', which has shape '(?, 4, 36)'"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"./model/capcha.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# go on training\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tf.train.latest_checkpoint('./model'))\n",
    "y_test = np.reshape(y_test, [-1, num_char, num_charmap])\n",
    "trainset_ge = generator(X_train, y_train, batch_size=128)\n",
    "num_loop = 20000\n",
    "print(time.ctime() ,\": train cnn begin, amount %d steps\"%num_loop)\n",
    "for i in range(num_loop):\n",
    "    X_batch, y_batch = next(trainset_ge)\n",
    "    y_batch = y_batch.reshape(-1, num_char, num_charmap)\n",
    "    if (i+1)%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:X_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        print(time.ctime() ,\": step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: X_batch, y_: y_batch, keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0485265"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 36)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = max_idx_p.eval(feed_dict={x:X_batch, keep_prob: 1.0})\n",
    "print([char_map[_i] for _i in pred] )\n",
    "plt.imshow(X_train[1].reshape((40, 100)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model/capcha.model'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2265625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.eval(feed_dict={x:X_batch, y_: y_batch, keep_prob: 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  5 23:31:21 2017 : train cnn begin, amount 20000 steps\n",
      "Thu Jan  5 23:34:56 2017 : step 99, training accuracy 0.234375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-3fd3ae1ebce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\": step %d, training accuracy %g\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m     \"\"\"\n\u001b[0;32m-> 1449\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3666\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3667\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3668\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   3670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Program Files\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Operation at 0x1fc84c2e208>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
